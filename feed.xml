<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://jiantingfeng.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jiantingfeng.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-20T07:53:15+00:00</updated><id>https://jiantingfeng.github.io/feed.xml</id><title type="html">Jianting Feng</title><subtitle>Jianting Feng - Postgraduate Student in Statistics at The Chinese University of Hong Kong </subtitle><entry><title type="html">Understanding Gradient Descent: The Backbone of Modern Machine Learning</title><link href="https://jiantingfeng.github.io/machine%20learning/optimization/2024/03/21/understanding-gradient-descent.html" rel="alternate" type="text/html" title="Understanding Gradient Descent: The Backbone of Modern Machine Learning"/><published>2024-03-21T03:00:00+00:00</published><updated>2024-03-21T03:00:00+00:00</updated><id>https://jiantingfeng.github.io/machine%20learning/optimization/2024/03/21/understanding-gradient-descent</id><content type="html" xml:base="https://jiantingfeng.github.io/machine%20learning/optimization/2024/03/21/understanding-gradient-descent.html"><![CDATA[<p>Gradient descent is one of the most fundamental optimization algorithms in machine learning. It’s the workhorse behind training neural networks, linear regression models, and many other machine learning algorithms. In this post, we’ll explore what gradient descent is, how it works, and why it’s so important in modern machine learning.</p> <h2 id="table-of-contents">Table of Contents</h2> <ul> <li><a href="#table-of-contents">Table of Contents</a></li> <li><a href="#what-is-gradient-descent">What is Gradient Descent?</a></li> <li><a href="#the-mathematics-behind-gradient-descent">The Mathematics Behind Gradient Descent</a></li> <li><a href="#types-of-gradient-descent">Types of Gradient Descent</a> <ul> <li><a href="#1-batch-gradient-descent">1. Batch Gradient Descent</a></li> <li><a href="#2-stochastic-gradient-descent-sgd">2. Stochastic Gradient Descent (SGD)</a></li> <li><a href="#3-mini-batch-gradient-descent">3. Mini-batch Gradient Descent</a></li> </ul> </li> <li><a href="#practical-implementation">Practical Implementation</a></li> <li><a href="#key-considerations">Key Considerations</a> <ul> <li><a href="#learning-rate-selection">Learning Rate Selection</a></li> <li><a href="#feature-scaling">Feature Scaling</a></li> <li><a href="#convergence-criteria">Convergence Criteria</a></li> </ul> </li> <li><a href="#conclusion">Conclusion</a></li> <li><a href="#references">References</a></li> </ul> <h2 id="what-is-gradient-descent">What is Gradient Descent?</h2> <p>At its core, gradient descent is an iterative optimization algorithm used to minimize a function. In machine learning, this function is typically a loss function that measures how well our model is performing. The goal is to find the parameters that minimize this loss function.</p> <blockquote> <p><strong>Key Idea</strong>: Gradient descent works by iteratively moving in the direction of steepest descent, guided by the negative gradient of the function.</p> </blockquote> <h2 id="the-mathematics-behind-gradient-descent">The Mathematics Behind Gradient Descent</h2> <p>The basic idea is simple:</p> <ol> <li>Start at a random point in the parameter space</li> <li>Calculate the gradient (derivative) of the loss function at that point</li> <li>Move in the direction opposite to the gradient</li> <li>Repeat until convergence</li> </ol> <p>The update rule can be written as:</p> \[\theta_{t+1} = \theta_t - \eta \nabla J(\theta_t)\] <p>where:</p> <ul> <li>$\theta_t$ represents the parameters at step t</li> <li>$\eta$ is the learning rate</li> <li>$\nabla J(\theta_t)$ is the gradient of the loss function</li> </ul> <h2 id="types-of-gradient-descent">Types of Gradient Descent</h2> <p>There are three main variants of gradient descent, each with its own advantages and trade-offs:</p> <h3 id="1-batch-gradient-descent">1. Batch Gradient Descent</h3> <ul> <li>Uses the entire training dataset to compute the gradient at each step</li> <li>Provides stable convergence but can be computationally expensive</li> <li>Best for small to medium-sized datasets</li> </ul> <h3 id="2-stochastic-gradient-descent-sgd">2. Stochastic Gradient Descent (SGD)</h3> <ul> <li>Uses a single training example at a time</li> <li>Faster updates but more noisy convergence</li> <li>Good for large datasets and online learning</li> </ul> <h3 id="3-mini-batch-gradient-descent">3. Mini-batch Gradient Descent</h3> <ul> <li>Uses a small subset of the training data</li> <li>Balances computational efficiency and convergence stability</li> <li>Most commonly used in practice</li> </ul> <h2 id="practical-implementation">Practical Implementation</h2> <p>Here’s a clean implementation of gradient descent for linear regression in Python:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Perform gradient descent optimization for linear regression.
    
    Parameters:
    -----------
    X : numpy.ndarray
        Feature matrix of shape (m, n)
    y : numpy.ndarray
        Target vector of shape (m,)
    learning_rate : float
        Step size for each iteration
    num_iterations : int
        Number of iterations to perform
        
    Returns:
    --------
    numpy.ndarray
        Optimized parameters
    </span><span class="sh">"""</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
        <span class="c1"># Calculate gradient
</span>        <span class="n">gradient</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
        <span class="c1"># Update parameters
</span>        <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient</span>
        
    <span class="k">return</span> <span class="n">theta</span>
</code></pre></div></div> <h2 id="key-considerations">Key Considerations</h2> <p>When implementing gradient descent, several factors need to be carefully considered:</p> <h3 id="learning-rate-selection">Learning Rate Selection</h3> <ul> <li>Too large: Algorithm might diverge</li> <li>Too small: Slow convergence</li> <li>Solution: Use learning rate scheduling or adaptive methods</li> </ul> <h3 id="feature-scaling">Feature Scaling</h3> <ul> <li>Scale features to similar ranges</li> <li>Improves convergence stability</li> <li>Common methods: Standardization, Normalization</li> </ul> <h3 id="convergence-criteria">Convergence Criteria</h3> <ul> <li>Maximum number of iterations</li> <li>Loss function change threshold</li> <li>Validation set performance</li> </ul> <h2 id="conclusion">Conclusion</h2> <p>Gradient descent is a powerful and versatile optimization algorithm that forms the foundation of many machine learning models. Understanding its mechanics and variations is crucial for anyone working in the field of machine learning and optimization.</p> <p>In future posts, we’ll explore more advanced topics like:</p> <ul> <li>Adaptive learning rates</li> <li>Momentum and Nesterov acceleration</li> <li>Second-order optimization methods</li> </ul> <p>Stay tuned for more insights into the fascinating world of machine learning optimization!</p> <h2 id="references">References</h2> <ol> <li>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). Deep Learning. MIT Press.</li> <li>Bottou, L. (2012). Stochastic gradient descent tricks. In Neural Networks: Tricks of the Trade.</li> </ol>]]></content><author><name></name></author><category term="Machine Learning"/><category term="Optimization"/><category term="gradient-descent"/><category term="optimization"/><category term="machine-learning"/><summary type="html"><![CDATA[Gradient descent is one of the most fundamental optimization algorithms in machine learning. It’s the workhorse behind training neural networks, linear regression models, and many other machine learning algorithms. In this post, we’ll explore what gradient descent is, how it works, and why it’s so important in modern machine learning.]]></summary></entry></feed>